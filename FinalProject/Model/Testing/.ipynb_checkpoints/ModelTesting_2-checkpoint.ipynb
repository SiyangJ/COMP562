{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#set FLAG and get data\n",
    "class BaseConfig(object):\n",
    "    seq_lenght=20      #seq lenght\n",
    "    batch_size=64      #batch_size\n",
    "    feature_num=1      #dim of a seq\n",
    "    lstm_size=64   #hidden layer units\n",
    "    lstm_layers=6\n",
    "    keep_prob=0.5\n",
    "    lr=0.00001        #learn rate\n",
    "    sep=0.9         #train and test sep\n",
    "    epoch_size=10000 #train number\n",
    "    \n",
    "config=BaseConfig()\n",
    "\n",
    "sp500=pd.read_csv('sp500.csv')\n",
    "data=sp500['Close']\n",
    "data_shift1=data.shift(1)\n",
    "data_diff1=(data-data_shift1)[1:]\n",
    "#以折线图展示data\n",
    "#plt.figure()\n",
    "#plt.plot(data)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def division_data(data,config,regular=True):\n",
    "    #data:np.array([1,2,3,4,5,6,7,8])\n",
    "    #all_data\n",
    "    if regular:\n",
    "        data=(np.array(data)-np.array(data).mean())/np.array(data).std()\n",
    "        \n",
    "    X,y=[],[]\n",
    "    for i in range(len(data) - config.seq_lenght-1):\n",
    "        X.append(data[i:i+config.seq_lenght])\n",
    "        y.append(data[i+config.seq_lenght]+1)\n",
    "    X=np.array(X)[:,:,np.newaxis]\n",
    "    y=np.array(y)[:,np.newaxis]\n",
    "    #index\n",
    "    train_size=int(config.sep*len(X))\n",
    "    split_index=[1]*train_size\n",
    "    split_index.extend([0] * (len(X) - train_size))\n",
    "    np.random.shuffle(split_index)\n",
    "\n",
    "    #division all_data into train and test data\n",
    "    train_X,train_y,test_X,test_y=[],[],[],[]\n",
    "    for i,v in enumerate(split_index):\n",
    "        if v==0:\n",
    "            test_X.append(X[i])\n",
    "            test_y.append(y[i])\n",
    "        else:\n",
    "            train_X.append(X[i])\n",
    "            train_y.append(y[i])\n",
    "    train_X=np.array(train_X).astype('float32')\n",
    "    train_y=np.array(train_y).astype('float32')\n",
    "    test_X=np.array(test_X).astype('float32')\n",
    "    test_y=np.array(test_y).astype('float32')\n",
    "    return train_X,train_y,test_X,test_y\n",
    "train_X,train_y,test_X,test_y=division_data(data_diff1,config)\n",
    "\n",
    "\n",
    "\n",
    "#general W\n",
    "def W_var(in_dim,out_dim):\n",
    "    return tf.Variable(tf.random_normal([in_dim,out_dim]),tf.float32)\n",
    "\n",
    "#general b\n",
    "def b_var(out_dim):\n",
    "    return tf.Variable(tf.random_normal([out_dim,]),tf.float32)\n",
    "\n",
    "#lstm : 64 lstm_size, 2 lstm_layer\n",
    "\n",
    "def lstm_cell(config,keep_prob):\n",
    "    temp=tf.contrib.rnn.BasicLSTMCell(config.lstm_size)\n",
    "    drop = tf.nn.rnn_cell.DropoutWrapper(temp, output_keep_prob=keep_prob)\n",
    "    return drop\n",
    "\n",
    "def lstm_layers(config,X,keep_prod):\n",
    "    #input\n",
    "    \n",
    "    stacked_lstm = tf.contrib.rnn.MultiRNNCell(\n",
    "    [lstm_cell(config,keep_prod) for _ in range(config.lstm_layers)])\n",
    "    initial_state = stacked_lstm.zero_state(config.batch_size, tf.float32)\n",
    "    \n",
    "    outputs, final_state = tf.nn.dynamic_rnn(stacked_lstm, X, \n",
    "          initial_state=initial_state)\n",
    "    return outputs,final_state\n",
    "        \n",
    "def output_layers(config,output_lstm):\n",
    "    in_size=output_lstm.get_shape()[-1].value\n",
    "    output_lstm=output_lstm[:,-1,:]\n",
    "    output_lstm=tf.reshape(output_lstm,[-1,in_size])\n",
    "    W=W_var(in_size,config.feature_num)\n",
    "    b=b_var(config.feature_num)\n",
    "    output_final=tf.add(tf.matmul(output_lstm,W),b)\n",
    "    return output_final\n",
    "\n",
    "def loss_function(output_final,Y):\n",
    "    print(output_final.shape,Y.shape)\n",
    "    loss=tf.reduce_mean(tf.square(output_final-Y))\n",
    "    return loss\n",
    "\n",
    "def optimizer_function(config,loss):\n",
    "    opt=tf.train.AdamOptimizer(config.lr).minimize(loss)\n",
    "    return opt\n",
    "\n",
    "\n",
    "class train_body:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.X_placehold=tf.placeholder(tf.float32, [None,config.seq_lenght,config.feature_num])\n",
    "        self.Y_placehold=tf.placeholder(tf.float32, [None,1])\n",
    "        self.keep_prod=tf.placeholder(tf.float32)\n",
    "        self.output_lstm,_=lstm_layers(config,self.X_placehold,self.keep_prod)\n",
    "\n",
    "        self.output_final=output_layers(config,self.output_lstm)\n",
    "\n",
    "        self.loss=loss_function(self.output_final,self.Y_placehold)\n",
    "\n",
    "        self.opt=optimizer_function(config,self.loss)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def myrun():\n",
    "    \n",
    "    tb=train_body()\n",
    "\n",
    "    #save model\n",
    "\n",
    "    saver=tf.train.Saver(tf.global_variables())\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        range(int(len(train_X)/config.batch_size))\n",
    "\n",
    "        for e in range(config.epoch_size):\n",
    "            loss_values1=np.array([])\n",
    "            for i in range(int(len(train_X)/config.batch_size)):\n",
    "                \n",
    "                tempx=train_X[i*config.batch_size:i*config.batch_size+config.batch_size]\n",
    "                tempy=train_y[i*config.batch_size:i*config.batch_size+config.batch_size]\n",
    "                #print(tempx)\n",
    "                tmp_loss_value,_=sess.run([tb.loss,tb.opt],feed_dict={tb.X_placehold:tempx,tb.Y_placehold:tempy,tb.keep_prod:0.5})\n",
    "                loss_values1=np.append(loss_values1,tmp_loss_value)\n",
    "                \n",
    "            if e%10==0:\n",
    "                loss_values2=np.array([])\n",
    "                for i in range(int(len(test_X)/config.batch_size)):\n",
    "\n",
    "                    tempx=test_X[i*config.batch_size:i*config.batch_size+config.batch_size]\n",
    "                    tempy=test_y[i*config.batch_size:i*config.batch_size+config.batch_size]\n",
    "                    #print(tempx)\n",
    "                    tmp_loss_value=sess.run([tb.loss],feed_dict={tb.X_placehold:tempx,tb.Y_placehold:tempy,tb.keep_prod:1})\n",
    "                    loss_values2=np.append(loss_values2,tmp_loss_value)\n",
    "               \n",
    "                print('std is: ',train_y.std())\n",
    "                print('ephoch: '+ str(e)+'\\ntrain loss is: '+str(loss_values1.mean())\n",
    "                      +'; test loss is: ' + str(loss_values2.mean()))\n",
    "                #print('ephoch: '+ str(e)+'\\ntrain loss is: '+str(loss_values1.mean()))\n",
    "                print (\"save model:\",saver.save(sess,'./sp500_model/sp500.model\\n'))\n",
    "\n",
    "myrun()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
