{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# COMP 562 â€“ Lecture 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Commonly Used Discrete Distributions -- Bernoulli\n",
    "\n",
    "\n",
    "Bernoulli distributed random variable X will be denoted as\n",
    "\n",
    "$$\n",
    "X \\sim \\textrm{Bernoulli}(\\theta)\n",
    "$$\n",
    "\n",
    "State space is $\\{0,1\\}$ -- think coin toss, parameter $\\theta \\in [0,1]$ specifies probability of one of the outcomes\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(X = 1|\\theta) &= \\theta \\\\\n",
    "p(X = 0|\\theta) &= 1 - \\theta.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that we can write this out more compactly as:\n",
    "\n",
    "$$\n",
    "p(X = x|\\theta) = \\theta^x(1-\\theta)^{1-x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Commonly Used Discrete Distributions -- Categorical\n",
    "\n",
    "Categorical distribution is a generalization of Bernoulli to more than two outcomes -- rollin a $k$-sided die\n",
    "\n",
    "$$\n",
    "X \\sim \\textrm{Categorical}(\\theta_1,\\theta_2,...,\\theta_{k-1})\n",
    "$$\n",
    "\n",
    "State space is $\\{1,2,3,...,k\\}$. Parameters $\\theta_1,..\\theta_{k-1}$ specify probability of outcomes $1,...k-1$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(X = 1|\\theta_1,..\\theta_{k-1}) &= \\theta_1 \\\\\n",
    "p(X = 2|\\theta_1,..\\theta_{k-1}) &= \\theta_2 \\\\\n",
    "...\\\\\n",
    "p(X = k-1|\\theta_1,..\\theta_{k-1}) &= \\theta_2 \\\\\n",
    "p(X = k|\\theta_1,..\\theta_{k-1}) &= 1 - \\sum_{i=1}^{k-1} \\theta_{k-1} = \\theta_k\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We note that $\\theta_k$ is not a parameter but rather computed from parameters for convience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Commonly Used Discrete Distributions -- Binomial and Multinomial\n",
    "\n",
    "Binomial and Multinomial distributions are generalizations of Bernoulli and Categorical distributrions\n",
    "\n",
    "Instead of a single trial, a coin toss or die roll, we consider outcomes across multiple trials, multiple coin tosses and die rolls\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X &\\sim \\textrm{Binomial}(n,\\theta)\\\\ \\\\\n",
    "p(X = k|n,\\theta) &= \\binom{n}{k}\\theta^k(1-\\theta)^{n-k}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\binom{n}{k} = \\frac{n!}{(n-k)!k!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A random variable distributed according to Multinomial distribution is a vector of counts\n",
    "\n",
    "For example, count of 1s, 2s, 3s, 4s, 5s, 6s observed after multiple six dies rolls\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "X = (X_1,X_2,...,X_k) &\\sim \\textrm{Multinomial}(n,\\theta)\\\\\n",
    "p(X = \\mathbf{x}|n,\\theta) &= \\binom{n}{x_1\\dots x_k }\\prod_{j=1}^k\\theta_j^{x_j}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\binom{n}{x_1\\dots x_k } = \\frac{n!}{x_1!x_2!\\cdots x_k!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Commonly Used Continuous Distributions -- Gaussian\n",
    "\n",
    "$X$ is distributed according to normal (or Gaussian) distribution with mean $\\mu$ and variance $\\sigma^2$\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "X &\\sim \\mathcal{N}(\\mu,\\sigma^2) \\\\ \\\\\n",
    "p(X = x|\\mu,\\sigma^2)&= \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that the variance is $\\sigma^2$ and standard deviation is $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Commonly Used Continuous Distributions -- Laplace\n",
    "\n",
    "\n",
    "$X$ is distributed according to Laplace distribution with location $\\mu$ and scale $b$\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "X &\\sim \\textrm{Laplace}(\\mu,b) \\\\ \\\\\n",
    "p(X = x|\\mu,b))&= \\frac{1}{2b}\\exp{\\left\\{-\\frac{|x - \\mu|}{b}\\right\\}} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Location and scale are analogous to mean and variance in normal distribution\n",
    "\n",
    "Note:for Laplace distibution: mean = $\\mu$ and variance is = $2b^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parameters and Likelihood Function\n",
    "\n",
    "Each of the coin tosses can be thought of as a realization of a random variable\n",
    "\n",
    "Hence we can write probability of the data $\\mathbf{x}$\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}|\\theta) = \\prod_{i=1}^N p(X = x_i|\\theta) = \\prod_{i=1}^N \\theta^{x_i}(1-\\theta)^{1-x_i}\n",
    "$$\n",
    "\n",
    "Pluging in different $\\theta$s give different probability of the data\n",
    "\n",
    "**<font color='red'> Q: Could this help us figure out what the next toss could be? </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parameters and Likelihood Function\n",
    "\n",
    "Hence, we can try to find parameter $\\theta$ for which $p(\\mathbf{x}|\\theta)$ is the largest\n",
    "\n",
    "$p(\\mathbf{x}|\\theta)$ can be seen as a function of **parameter** $\\theta$\n",
    "\n",
    "This function is called *likelihood* \n",
    "\n",
    "$$\n",
    "\\mathcal{L(\\theta|\\mathbf{x})} = p(\\mathbf{x}|\\theta)\n",
    "$$\n",
    "\n",
    "$\\theta$ which results in the largest likelihood is called **maximum-likelihood estimate**\n",
    "\n",
    "In many cases, learning is nothing more than maximizing likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Log-Likelihood\n",
    "\n",
    "Maximization of likelihood can be tricky when datasets are large, computing product of probabilities, by definition smaller than 1, can easily underflow\n",
    "\n",
    "Typically, we maximize likelihood by finding maxima of log-likelihood, the location of the maximum's of these two functions coincide, and the only difference is that we avoid numerical problems\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta|\\mathbf{x}) = \\log p(\\mathbf{x}|\\theta) = \\log \\prod_i p(x_i|\\theta) = \\sum_i \\log p(x_i|\\theta)\n",
    "$$\n",
    "\n",
    "In general, we will compute log probabilities and only convert them to probabilities when we need to perform marginalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Maximizing Likelihood \n",
    "\n",
    "Log-Likelihood in detail:\n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta|\\mathbf{x}) = \\sum_i \\log p(x_i|\\theta)\n",
    "$$\n",
    "We plug in our Bernoulli distribution\n",
    "$$\n",
    "p(x_i|\\theta) = \\theta^{x_i} (1-\\theta)^{1 - x_i}\n",
    "$$\n",
    "and it's log is\n",
    "$$\n",
    "\\log p(x_i|\\theta) = {x_i}\\log \\theta + (1-x_i)\\log(1-\\theta)\n",
    "$$\n",
    "Putting it all together\n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta|\\mathbf{x}) = \\sum_i \\left[{x_i}\\log \\theta + (1-x_i)\\log(1-\\theta)\\right]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Maximizing Likelihood  \n",
    "\n",
    "Our coin toss example:\n",
    "\n",
    "Data: $$\n",
    "\\mathbf{x} = \\{0,1,0,0,1,0,1,0,1,...\\}\n",
    "$$\n",
    "Log-Likelihood: \n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta|\\mathbf{x}) = \\log p(\\mathbf{x}|\\theta) = \\log \\prod_i p(x_i|\\theta) = \\sum_i \\log p(x_i|\\theta)\n",
    "$$\n",
    "Maximum likelihood estimate: $$\\theta^{\\textrm{ML}} = \\mathop{\\textrm{argmax}}_\\theta \\log \\mathcal{L}(\\theta|\\mathbf{x})$$\n",
    "\n",
    "**<font color='red'> Q: How do we find maxima/minima of functions? </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Finding Maximum/Minimum of log-Likelihood\n",
    "\n",
    "Coin toss example again:\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta|\\mathbf{x}) = \\sum_i \\left[{x_i}\\log \\theta + (1-x_i)\\log(1-\\theta)\\right]\n",
    "$$\n",
    "\n",
    "Let's compute first derivative\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta}\\log \\mathcal{L}(\\theta|\\mathbf{x}) = \\sum_i \\left[{x_i}\\frac{1}{\\theta} + (1-x_i)(-\\frac{1}{1 - \\theta})\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To find best $\\theta$ we equate the derivative $\\frac{\\partial}{\\partial \\theta}\\log \\mathcal{L}(\\theta|\\mathbf{x})$ to zero  and solve\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta}\\log \\mathcal{L}(\\theta|\\mathbf{x}) = 0 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Finding Maximum/Minimum of log-Likelihood\n",
    "\n",
    "For our coin toss example this amounts to:\n",
    "\n",
    "$$\n",
    "%\\begin{aligned}\n",
    "\\sum_i \\left[{x_i}\\frac{1}{\\theta} + (1-x_i)\\frac{-1}{1 - \\theta}\\right] = 0\\\\\n",
    "\\sum_i {x_i}\\frac{1}{\\theta} - \\sum_i (1-x_i)\\frac{1}{1 - \\theta} = 0\\\\\n",
    "\\sum_i {x_i}\\frac{1}{\\theta} = \\sum_i (1-x_i)\\frac{1}{1 - \\theta} \\\\\n",
    "\\frac{1}{\\theta}\\underbrace{\\sum_i {x_i}}_{n_h} = \\frac{1}{1 - \\theta}\\underbrace{\\sum_i (1-x_i)}_{n_t} \\\\\n",
    "%\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "$$\n",
    "%\\begin{aligned}\n",
    "(1 - \\theta)n_h = \\theta n_t \\\\ \\\\\n",
    "n_h  = \\theta (n_t+n_h)\\\\ \\\\\n",
    "\\theta = \\frac{n_h}{n_t + n_h}\n",
    "%\\end{aligned}\n",
    "$$\n",
    "\n",
    "Anti-climactic? Reassuring? From the first principles?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
